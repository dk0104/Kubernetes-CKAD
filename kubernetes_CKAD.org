#+TITLE: Kubernetes CKAD
#+SETUPFILE: https://fniessen.github.io/org-html-themes/setup/theme-readtheorg.setup
* Certification nontes
** Setup alias etc.
[[https://kubernetes.io/docs/reference/kubectl/cheatsheet/][cheat sheet]]
#+begin_src  shell
alias k = kubectl
complete -F __start_kubectl k
#+end_src

- use --dry-run=client
- use -o yaml to create resource definition file
- read  [[https://kubernetes.io/docs/reference/kubectl/conventions/][conventions]]
- use explain commands
#+BEGIN_SRC
kubectl explain <opject> --recursive
// explain extendet

#+END_SRC
-  Avoid running "kubectl edit pod <pod name>" use "kubectl get pod <name> -o yaml > <name>.yaml" instead
- some useful imperative commands
| command                                                                     | description       |
|-----------------------------------------------------------------------------+-------------------|
| kubectl run nginx --image=nginx --restart=Never                             | create Pod        |
| kubectl run nginx --image=nginx --restart=OnFailure                         | create Job        |
| kubectl run nginx --image=nginx  --restart=OnFailure --schedule="* * * * *" | create cronJob    |
|                                                                             |                   |
** [[Service]]

#+BEGIN_QUOTE
An abstract way to expose an application running on a set of Pods as a network service.
With Kubernetes you don't need to modify your application to use an unfamiliar service discovery mechanism. Kubernetes gives Pods their own IP addresses and a single DNS name for a set of Pods, and can load-balance across them.
#+END_QUOTE


Create a Service named redis-service of type ClusterIP to expose pod redis on port 6379
#+BEGIN_SRC
kubectl expose pod redis --port=6379 --name redis-service --dry-run=client -o yaml
#+END_SRC
(This will automatically use the pod's labels as selectors)

Or
#+BEGIN_SRC
kubectl create service clusterip redis --tcp=6379:6379 --dry-run=client -o yaml
#+END_SRC
(This will not use the pods labels as selectors, instead it will assume selectors as app=redis. You cannot pass in selectors as an option. So it does not work very well if your pod has a different label set. So generate the file and modify the selectors before creating the service)

Create a Service named nginx of type NodePort to expose pod nginx's port 80 on port 30080 on the nodes:
#+BEGIN_SRC
kubectl expose pod nginx --port=80 --name nginx-service --type=NodePort --dry-run=client -o yaml
#+END_SRC
(This will automatically use the pod's labels as selectors, but you cannot specify the node port. You have to generate a definition file and then add the node port in manually before creating the service with the pod.)

Or

#+BEGIN_SRC
kubectl create service nodeport nginx --tcp=80:80 --node-port=30080 --dry-run=client -o yaml
#+END_SRC

(This will not use the pods labels as selectors)
Both the above commands have their own challenges. While one of it cannot accept a selector the other cannot accept a node port. I would recommend going with the `kubectl expose` command. If you need to specify a node port, generate a definition file using the same command and manually input the nodeport before creating the service

* kubectl api
[[https://kubernetes.io/docs/reference/kubectl/cheatsheet/][Kubernetes docs cheat sheet ]]
** delete
| command                                    |                          |
|--------------------------------------------+--------------------------|
| kubectl delete pod <name> --grace-period=0 | Delete pod with no delay |
|                                            |                          |

** run

| command                                                                 | description                       |
|-------------------------------------------------------------------------+-----------------------------------|
| k run nginx --image=nginx --restart=Never                               | create Pod                        |
| k run nginx --image=nginx --restart=OnFailure                           |                                   |
| k run nginx --image=nginx  --restart=OnFailure --schedule="* * * * *"   | create cronJob                    |
| k run <name> --image=<image> --restart=Never -it --rm --echo "tex"      | create and send output            |
| k run <name> --image=<image> --labes=<label key>=<label val>            | create pod with labels            |
| k run <name> --image=<image> --restart=Never -- /bin/sh -c "sleep 3600" | create pod with sleep cmd command |
|                                                                         |                                   |

** exec

| Description             | Command                                 |
|-------------------------+-----------------------------------------|
| Exec into the pod       | kubectl exec --it <name> /bin/sh        |
| Run command on multipod | kubectl exec <name> -c <container name> |
|                         |                                         |

** create
[[https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#create][create doc link]]

| Description        | Command                                           |
|--------------------+---------------------------------------------------|
| Create deployment  | kubectl create deployment <name> --image=<image>  |
| Create secret      | kubectl create secret generic dev-db-secret \     |
|                    | --from-literal=username=devuser \                 |
|                    | --from-literal=password='S!B\*d$zDsb='            |
| Create secret file | kubectl create secret genereic --from-file=<path> |
|                    |                                                   |

#+BEGIN_SRC shell
kubectl create <type>
#+END_SRC
| Type                | Description                                |
|---------------------+--------------------------------------------|
| clusterrole         | Cluster Role                               |
| clusterrollebinding | Cluster role binding for part. clusterrole |
| configmap           | Config maps                                |
| conjob              | cronjob ]                                  |
| deployment          | Deployment                                 |
| job                 | Create Job                                 |
| mamspace            |                                            |
| poddisruptionbudget | pod distruption budget                     |
| priorityclass       |                                            |
| quota               |                                            |
| role                | role with specified name.                  |
| rolebinding         | RoleBinding                                |
| secret              | secret                                     |
| service             |                                            |
| serviceaccount      | Service account with specfied naem         |

*** Generators
| kubectl create <genereator> --dry-run=client -o yaml |                                                                   |
| clusterrole                                          | Create a ClusterRole.                                             |
| clusterrolebinding                                   | Create a ClusterRoleBinding for a particular ClusterRole.         |
| configmap                                            | Create a configmap from a local file, directory or literal value. |
| cronjob                                              | Create a cronjob with the specified name.                         |
| deployment                                           | Create a deployment with the specified name.                      |
| job                                                  | Create a job with the specified name.                             |
| namespace                                            | Create a namespace with the specified name.                       |
| poddisruptionbudget                                  | Create a pod disruption budget with the specified name.           |
| priorityclass                                        | Create a priorityclass with the specified name.                   |
| quota                                                | Create a quota with the specified name.                           |
| role                                                 | Create a role with single rule.                                   |
| rolebinding                                          | Create a RoleBinding for a particular Role or ClusterRole.        |
| secret                                               | Create a secret using specified subcommand.                       |
| service                                              | Create a service using specified subcommand.                      |
| serviceaccount                                       | Create a service account with the specified name.                 |
|                                                      |                                                                   |

** describe
*** get labels
#+begin_src  shell

k describe  <node> | less
/Labels

#+end_src


| Description | Command |
|-------------+---------|
|             |         |

** get

get pod,pods, pv ,services,node,nodes,events    ,
| Description                                                | Command                                                                                            |
|------------------------------------------------------------+----------------------------------------------------------------------------------------------------|
| Show secrets                                               | k get secrets                                                                                      |
| Check the image version                                    | k get pod <name> -o jsonpath='.spec.containers[].image{"\n}                                        |
| list sorted                                                | k get pods--sort-by=.metadata.creationTimestamp                                                    |
| Get pods with labels                                       | k get pods --show-labels                                                                           |
| Get pod with sertain labels                                | k get pods -l <label val>=<label key> --show labels                                                |
| Get pods with label keys                                   | k get pods -L env                                                                                  |
| Get pods with multi label key val pair                     | k get pods -l '<label key> in <val1,val2>' --show-labels                                           |
| List the pod with different verbosity                      | k get po nginx --v=7                                                                               |
| List the nginx pod with custom columns POD_NAME POD_STATUS | k get po -o=custom-columns='POD_NAME:.metadata.name, POD_STATUS:.status.containerStatuses[].state' |
| List all pods sorted by  name                              | k get pods --sort-by=.metadata.name                                                                |

*** List the nginx pod with custom columns POD_NAME POD_STATUS
#+BEGIN_SRC shell
kubectl get po -o=custom-columns='POD_NAME:.metadata.name, POD_STATUS:.status.containerStatuses[].state'
#+END_SRC

#+RESULTS:
| POD_NAME     | POD_STATUS                                                                                               |              |                                 |              |                                  |
| nginx        | map[running:map[startedAt:2020-10-20T07:29:32Z]]                                                         |              |                                 |              |                                  |
| nginx2       | map[terminated:map[containerID:docker://db3b1fc303903f6f8d2468862cba9421b3b48317574c1fb2d89f1a294c8e9fa7 | exitCode:127 | finishedAt:2020-10-20T06:23:10Z | reason:Error | startedAt:2020-10-20T06:23:10Z]] |
| pod-readines | map[running:map[startedAt:2020-10-20T05:49:57Z]]                                                         |              |                                 |              |                                  |
| test         | map[running:map[startedAt:2020-10-20T05:50:00Z]]                                                         |              |                                 |              |                                  |

*** Get pods with labels
#+BEGIN_SRC shell
kubectl get pods --show-labels
#+END_SRC

#+RESULTS:
| NAME         | READY | STATUS  | RESTARTS | AGE   | LABELS           |
| nginx        | 1/1   | Running |        0 | 73m   | run=nginx        |
| nginx2       | 0/1   | Error   |        0 | 139m  | run=nginx2       |
| pod-readines | 1/1   | Running |        1 | 3d16h | run=pod-readines |
| test         | 1/1   | Running |        1 | 3d17h | run=test         |

** edit

| Description                        | Command                        |
|------------------------------------+--------------------------------|
| Edit pod (not ediatble if running) | kubectl edit pod<name>         |
| Edit deployment                    | kubectl edit deployment <name> |

** logs

| Description             | Command                                 |
|-------------------------+-----------------------------------------|
| logs multiple contaiers | kubectl logs <name> -c <container name> |

** label

| Description      | Command                                  |
|------------------+------------------------------------------|
| change the label | kubectl label <name> env=uat --overwrite |
|                  |                                          |

** Patching resources
#+begin_src shell
# Partially update a node
kubectl patch node k8s-node-1 -p '{"spec":{"unschedulable":true}}'

# Update a container's image; spec.containers[*].name is required because it's a merge key
kubectl patch pod valid-pod -p '{"spec":{"containers":[{"name":"kubernetes-serve-hostname","image":"new image"}]}}'

# Update a container's image using a json patch with positional arrays
kubectl patch pod valid-pod --type='json' -p='[{"op": "replace", "path": "/spec/containers/0/image", "value":"new image"}]'

# Disable a deployment livenessProbe using a json patch with positional arrays
kubectl patch deployment valid-deployment  --type json   -p='[{"op": "remove", "path": "/spec/template/spec/containers/0/livenessProbe"}]'

# Add a new element to a positional array
kubectl patch sa default --type='json' -p='[{"op": "add", "path": "/secrets/1", "value": {"name": "whatever" } }]

#+end_src

** EXAMPLES

* how tos
** List and search
#+begin_src shell
k get nodes -o json | jq '.items[].spec.taints'

#+end_src
** Export pod to yaml
#+begin_src shell
k get pod <name> -o yaml > filename
#+end_src


* Core Concepts
** Node
- Apply lable on the nodes
** [[Deployment]]
Orig link: [[https://kubernetes.io/docs/concepts/services-networking/service/][Service]]

#+BEGIN_QUOTE
A Deployment provides declarative updates for Pods ReplicaSets.

You describe a desired state in a Deployment, and the Deployment Controller changes the actual state to the desired state at a controlled rate. You can define Deployments to create new ReplicaSets, or to remove existing Deployments and adopt all their resources with new Deployments.
#+END_QUOTE

example file
#+BEGIN_SRC

apiVersion: apps/v1
kind: Deployment
metadata:
name: nginx-deployment
labels:
    app: nginx
spec:
replicas: 3
selector:
matchLabels:
    app: nginx
template:
metadata:
    labels:
    app: nginx
spec:
containers:
- name: nginx
    image: nginx:1.14.2
    ports:
    - containerPort: 80
#+END_SRC

** Pod
- Create imperative pod
#+BEGIN_SRC
kubectl run <name> --image=<image>
#+END_SRC
- Create imperative podfile
#+BEGIN_SRC
`kubectl run <name> --image=<image> --dry-run=client -o yaml``
#+END_SRC
** Namespace
Doc link: [[https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/][Namespace]]
#+BEGIN_QUOTE
Kubernetes supports multiple virtual clusters backed by the same physical cluster. These virtual clusters are called namespaces.
#+END_QUOTE

How to use:

#+BEGIN_SRC shell

"List namespaces in cluster:"
kubectl get namespace

"Get elleenst for all namespaces"
kubectl get all -A

"Setting the namespace for a request"
kubectl run <name> --image=<image> --namespace=<namespace>
#+END_SRC

#+RESULTS:

** Deployment
[[https://kubernetes.io/docs/concepts/workloads/controllers/deployment/][Deployment]]
#+BEGIN_QUOTE
A Deployment provides declarative updates for Pods ReplicaSets.

You describe a desired state in a Deployment, and the Deployment Controller changes the actual state to the desired state at a controlled rate. You can define Deployments to create new ReplicaSets, or to remove existing Deployments and adopt all their resources with new Deployments.
#+END_QUOTE

example file
#+BEGIN_SRC

apiVersion: apps/v1
kind: Deployment
metadata:
name: nginx-deployment
labels:
    app: nginx
spec:
replicas: 3
selector:
matchLabels:
    app: nginx
template:
metadata:
    labels:
    app: nginx
spec:
containers:
- name: nginx
    image: nginx:1.14.2
    ports:
    - containerPort: 80
#+END_SRC

- create simple deployment
#+BEGIN_SRC
kubectl create deployment --image=<image> <name>
#+END_SRC
- create simple deploymentfile
#+BEGIN_SRC
`kubectl create deployment --image=<image> <name> --dry-run=client -o yaml > <filename>
#+END_SRC
- Important no replicas param use "kubectl scale" instead
** Service
[[https://kubernetes.io/docs/concepts/services-networking/service/][Service]]

#+BEGIN_QUOTE
An abstract way to expose an application running on a set of Pods as a network service.
With Kubernetes you don't need to modify your application to use an unfamiliar service discovery mechanism. Kubernetes gives Pods their own IP addresses and a single DNS name for a set of Pods, and can load-balance across them.
#+END_QUOTE

*** How to use :
#+BEGIN_SRC yaml
apiVersion: v1


#+END_SRC

* Configuration
** Command and Arguments
- Doc link: [[https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/][Define a Command and Arguments for Container]]

#+BEGIN_SRC yaml
apiVersion: v1
kind: Pod
metadata:
name: command-demo
labels:
    purpose: demonstrate-command
spec:
containers:
- name: command-demo-container
    image: debian
    command: ["printenv"]
    args: ["HOSTNAME", "KUBERNETES_PORT"]
restartPolicy: OnFailure

#+END_SRC

#+begin_src yaml
apiVersion: v1
kind: Pod
metadata:
name: ubuntu-sleeper-2
spec:
containers:
- name: ubuntu
image: ubuntu
command:
    - "sleep"
    - "5000"
#+end_src

** Config Maps
Doc link: [[https://kubernetes.io/docs/concepts/configuration/configmap/][ConfigMaps]]

#+BEGIN_QUOTE
A ConfigMap is an API object used to store non-confidential data in key-value pairs. Pods can consume ConfigMaps as environment variables, command-line arguments, or as configuration files in a volume.
A ConfigMap allows you to decouple environment-specific configuration from your container images, so that your applications are easily portable.
#+END_QUOTE

*** How to create config maps:
- Imperative
#+BEGIN_SRC shell

"create configmapi literal"
kubectl create configmap <config-name> --from-literal=<key>=<value>

"create configmap config file"
kubectl create configmap <config-name> --from-file=<path-to-file>


#+END_SRC

- Declarative

#+BEGIN_SRC yaml

apiVersion: v1
kind: ConfigMap
metadata:
name: game-demo
data:
# property-like keys; each key maps to a simple value
player_initial_lives: "3"
ui_properties_file_name: "user-interface.properties"

# file-like keys
game.properties: |
enemy.types=aliens,monsters
player.maximum-lives=5
user-interface.properties: |
color.good=purple
color.bad=yellow
allow.textmode=true

#+END_SRC
#+BEGIN_SRC shell
kubectl create -f <filename>
#+END_SRC

*** How to inject config maps
#+BEGIN_SRC
"show exitsting maps"
kubectl get configmaps

"describe map"
kubectl describe configmaps

#+END_SRC

- Inject to pod's
+ Inject config file
#+BEGIN_SRC yaml
apiVersion: v1
kind: Pod
metadata:
spec:
containers:
envFrom:
- configMapRef:
    name: <config name>

#+END_SRC
+ Inject singe config

#+BEGIN_SRC yaml
apiVersion: v1
kind: Pod
metadata:
spec:
containers:
envFrom:
- configMapKeyRef:
    name: <config name>
    key: <key>
#+END_SRC

** Environment Variable
** Replica Sets
** Security Context
** Secret
[[https://kubernetes.io/docs/concepts/configuration/secret/][Secret]]
#+BEGIN_QUOTE
Kubernetes Secrets let you store and manage sensitive information, such as passwords, OAuth tokens, and ssh keys. Storing confidential information in a Secret is safer and more flexible than putting it verbatim in a Pod definition or in a container image. See Secrets design document for more information
#+END_QUOTE
*** how to use:
**** Imperative Way to create secrets:

#+BEGIN_SRC
kubectl create secret generic dev-db-secret \
--from-literal=username=devuser \
--from-literal=password='S!B\*d$zDsb='
#+END_SRC

#+BEGIN_SRC
kubectl create secret generic dev-db-secret \
--from-file=<path to file>
#+END_SRC

**** Declarative way to create secrets:
#+BEGIN_SRC
apiVersion: v1
kind: Secret
metadata:
name: app-secret

data:
<Key>: <value>
#+END_SRC

kubectl create -f <filename>

*** Simple way to encrypt secret using Base64 encryption
#+BEGIN_SRC shell
echo -n <value> | base64
#+END_SRC

*** View secrets:
#+BEGIN_SRC  shell

"Show secrets       "
kubectl get secrets

"describe secrets"
kubectl describe secrets

"show secret values "
kubectl get secret app-secret -o yaml
#+END_SRC

#+RESULTS:

*** Pod integration
#+BEGIN_SRC yaml
apiVersion: v1
kind: Pod

spec:
containers:
envFrom:
    - secretRef:
        name: <secret:name>

#+END_SRC
Secrets could be injected as Single value Environment variable or volume.

** Service Accounts
** Taints and Tolerations
Doc link:  [[https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/][Taints and toleration]]
#+BEGIN_QUOTE
Node affinity, is a property of Pods that attracts them to a set of nodes (either as a preference or a hard requirement). Taints are the opposite -- they allow a node to repel a set of pods.
Tolerations are applied to pods, and allow (but do not require) the pods to schedule onto nodes with matching taints.
Taints and tolerations work together to ensure that pods are not scheduled onto inappropriate nodes. One or more taints are applied to a node; this marks that the node should not accept any pods that do not tolerate the taints.
#+END_QUOTE

- How to:
- Taint Node
#+BEGIN_SRC
kubctl taint nodes node-name key=value:taint-effect
#+END_SRC
Taint-effect
| NoSchedule       | avoid placing the node on the pod             |
| PreferNoSchedule | try to avoid placing the pod on the node      |
| NoExecute        | Avoid new pods, existing pods will be evicted |
- Apply tolarations to pods
#+BEGIN_SRC yaml
apiVersion: v1
spec:
    tolarations:
    - key:"<key>"
    operator:"<operator>"
    value: "<value>"
#+END_SRC

** Resource Request
** Node Selectors
** Node Affinity
Operators :
|              |   |
|--------------+---|
| In           |   |
| NotIn        |   |
| Exists       |   |
| DoesNotExist |   |
| Gt           |   |
| Lt           |   |

** Pods+

* Observability
** Monitoring and Debug
** Logs
** Readiness and Liveness Probes
** Container Logging
** Liveness Probes
* Pod Design
** Labels and Selectors
[[https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/][Labels and Selectors]]
#+BEGIN_QUOTE
Labels are key/value pairs that are attached to objects, such as pods. Labels are intended to be used to specify identifying attributes of objects that are meaningful and relevant to users, but do not directly imply semantics to the core system. Labels can be used to organize and to select subsets of objects. Labels can be attached to objects at creation time and subsequently added and modified at any time. Each object can have a set of key/value labels defined. Each Key must be unique for a given object.
#+END_QUOTE

Main reason for filtering ( Bridge tags filters )

*** How to use:
- Filter manually
#+BEGIN_SRC
kubectl get pods --selector <label key>=<label val>
#+END_SRC
- Address pods on replica sets
Replica set definiton file
#+BEGIN_SRC
apiVersion: apps/v1
kind: ReplicaSet
...
spec:
replicas: <num of replicas>
selector:
    matchLabels:
    app: App1             | -> Connect replica sets to the pod
template:
    metadata:
    labels:
        app: App1
        function: Front-end | -> Pod labels

#+END_SRC

** Init Containers
- kubernetes doc ref: [[https://kubernetes.io/docs/concepts/workloads/pods/init-containers/][Init Containers]]

#+BEGIN_QUOTE
This page provides an overview of init containers: specialized containers that run before app containers in a Pod. Init containers can contain utilities or setup scripts not present in an app image.
You can specify init containers in the Pod specification alongside the containers array (which describes app containers).
#+END_QUOTE


#+BEGIN_SRC
apiVersion: v1
kind: Pod
metadata:
name: myapp-pod
labels:
app: myapp
spec:
containers:
- name: myapp-container
image: busybox:1.28
command: ['sh', '-c', 'echo The app is running! && sleep 3600']
initContainers:
- name: init-myservice
image: busybox:1.28
command: ['sh', '-c', "until nslookup myservice.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo waiting for myservice; sleep 2; done"]
- name: init-mydb
image: busybox:1.28
command: ['sh', '-c', "until nslookup mydb.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo waiting for mydb; sleep 2; done"]
#+END_SRC

** Jobs / Cron Jobs
Doc link :[[https://kubernetes.io/docs/concepts/workloads/controllers/job/][Jobs ]]
Doc link [[https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/][Cron Jobs]]:
- Jobs are ment to perform some tastks -> Pods in order to completion and not for ever like ReplicaSets
*** How to create a job
- Pod definition
#+BEGIN_SRC
apiVersion: v1
kind: Pod
metadata:
name: math-pod
spec:
containers:
- name:
    image:
    command: []
restartPolicy: Never                | Kubernetes does not restart the container
#+END_SRC


- Job definition
#+BEGIN_SRC
apiVersion: batch/v1                | May be changed
kind: Job
metadata:
name: math-pod
spec:
completions: <number of inst>       | only number of comnl runs count
parallelism: <num>                  | completed parallel
template:
spec:
containers:
    - name:
        image:
        command: []
restartPolicy: Never
#+END_SRC

*** How to use jobs
| Command                               | Description                    |
|---------------------------------------+--------------------------------|
| kubectl create -f job-definition.yaml | Create job with definition     |
| kubectl get jobs                      | List created jobs              |
| kubectl delete job <name>             | Delete job                     |
| kubectl logs <pod>                    | Job output standard pod output |
|                                       |                                |

** Rolling updates and Rollback in Deployment
*** Rollout and versioning
- Deployment strategy

*** Examles
| Command                                   | Description                     |
|-------------------------------------------+---------------------------------|
| kubectl rollout status <deployment name>  | Shows current deployment status |
| kubectl rollout history <deployment name> | Shows deployment history        |
| kubectl apply -f <depl definition file>   | Pod changed -> rollout trigger  |
** Sidecar Design Pattern
#+BEGIN_QUOTE
A sidecar adds functionality to an existing application. This functionality could be saving certain files in a certain location, copying files continuously from one location to another or for instance be terminate SSL and have your “legacy” web server run unchanged.
#+END_QUOTE

#+BEGIN_SRC yaml


#+END_SRC
* Secvices and Networking
** Network Policy
[[https://kubernetes.io/docs/concepts/services-networking/network-policies/][NetworkPolicy]]

#+BEGIN_QUOTE
If you want to control traffic flow at the IP address or port level (OSI layer 3 or 4), then you might consider using Kubernetes NetworkPolicies for particular applications in your cluster. NetworkPolicies are an application-centric construct which allow you to specify how a pod is allowed to communicate with various network "entities" (we use the word "entity" here to avoid overloading the more common terms such as "endpoints" and "services", which have specific Kubernetes connotations) over the network.

The entities that a Pod can communicate with are identified through a combination of the following 3 identifiers:

Other pods that are allowed (exception: a pod cannot block access to itself)
Namespaces that are allowed
IP blocks (exception: traffic to and from the node where a Pod is running is always allowed, regardless of the IP address of the Pod or the node)
When defining a pod- or namespace- based NetworkPolicy, you use a selector to specify what traffic is allowed to and from the Pod(s) that match the selector.

Meanwhile, when IP based NetworkPolicies are created, we define policies based on IP blocks (CIDR ranges).
#+END_QUOTE

- Examles:
#+BEGIN_SRC
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
name: test-network-policy
namespace: default
spec:
podSelector:
matchLabels:
role: db
policyTypes:
- Ingress
- Egress
ingress:
- from:
- ipBlock:
    cidr: 172.17.0.0/16
    except:
    - 172.17.1.0/24
- namespaceSelector:
    matchLabels:
        project: myproject
- podSelector:
    matchLabels:
        role: frontend
ports:
- protocol: TCP
port: 6379
egress:
- to:
- ipBlock:
    cidr: 10.0.0.0/24
ports:
- protocol: TCP
    port: 5978
#+END_SRC

* State Presistance
** Persistent Volumes
[[https://kubernetes.io/docs/concepts/storage/persistent-volumes/][Persistent Volumes]]
** Persistent Volume Claims
[[https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims][Persistant volume claim]]

#+BEGIN_SRC yalm
apiVersion:v1
kind: PersistentVolumeClaim
metadata:
name: myclaim
spec:
accessModes:
- ReadWriteOnce
volumeMode: Filesystem
resources:
requests:
    storage: 8Gi
storageClassName: slow
selector:
matchLabels:
    release: "stable"
matchExpressions:
    - {key: environment, operator: In, values: [dev]}

#+END_SRC
* Additional themes
** Authorization
*** Notes
- Need to structure access between different users and kubectl
Node Authorizer user -> cube api -> cubelet

*** RBAC Role Besed Access Control
- apiVersion: rbac.authorization.k8s.io/v1
- rules
developer-role.yaml
#+begin_src shell
apiVersion
kind
metadata:
name:
rules:
- apiGroups: [""]    / Api groups could be left as blank
resource:  ["pods"]
verbs: ["list","get","create", "update", "delete"]
resourceNames: ["red","blue"]
#+end_src

devuser-developer-binding.yaml
#+begin_src shell
apiVersion
kind
metadata
subjects:
- kind: User
name: dev-user
apiGroup: rbac.authorization.k8s.io
roleRef:
- kind: Role
name: developer
apiGroup: rbac.authorization.k8s.io
#+end_src

- namespace could be spec whithin the methadata
#+begin_src shell
methadata:
name:
namespace:
#+end_src

#+RESULTS:
*** Cluster Roles
- how to get non namespaced resources
#+begin_src shell
kubctl api-resources --namespaced=false # gets non namespaced resources
kubctl api-resources --namespaced=true # gets namespaced resources
#+end_src
- Management of non ns resources
- Non ms resource could be managed with clusterroles and clusterrolebindings
- ClusterRoles :
    - Cluster Admin role can be created
    - Can view nodes
    - Can create nodes
    - Can delete nodes
        #+begin_src shell
        # cluster-role-admin.yml
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRole
        metadata:
        name: cluster-administrator
        rules:
        - apiGroups: [""]
        resources: ["nodes"]
        verbs: ["list","get","create","delete"]
        #+end_src
        #+begin_src shell
        kubctl create -f cluster-admin-role.yaml
        #+end_src

        #+RESULTS:

    - Storage admin roule
    - Can view PVs
    - Can create PVs
    - Can delete PVs
    -
- Clusterbindings
    -
    -
    -

*** kubectl api for rbac
#+begin_src shell
kubctl get roles                        // provide roles
kubctl get rolebinding                  // provide role bindings
kubctl describe role developer          // desc dev role
kubctl describe rolebinding             // describe role bindings
# Check access to the cluster
kubctl auth can-i create deployments
kubctl auth can-i delete nodes
kubctl auth can-i delete nodes --as <user>
kubctl auth can-i delete nodes --as <user> --namespace test

#+end_src


** Admission Controllers
#+begin_quote
Anmisson Controller helps to implement better security messures to enforsce how the controller is uesed
#+end_quote


** Custom recource definition
- Custom recource definition CRD
  #+begin_src shell
  apiVersion: apiextensions.k8s.io/v1
  kind: CustomRecourceDefinition
  metadata:
    name: <name uri>
  spec:
    scope: Namespacd
    group: flights.com
    names:
      king: FligtTicket
      singular: flightticket
      plural: flighttickets

  #+end_src

* Tool ideas etc.
** Bash alias entries and settings
- alias entries

#+BEGIN_SRC sh
alias k='kubectl'
alias c="k create"
alias d="k delete"
alias de="k describe"
alias e="k edit"
alias ex="k exec -it"
alias g="k get"
alias l="k logs -f"
alias r="k run"
alias roll="k rollout"
alias kns="k config set-context --current --namespace"
alias n="de po | grep -i namespace -m 1"

export do="--dry-run=client -o yaml"
export f="--force --grace-period=0"
#+END_SRC

start autocomplition :
#+BEGIN_SRC shell
complete -F __start_kubectl k
#+END_SRC

#inside .vimrc
#+BEGIN_SRC
set ts=2 sw=2 expandtab
set nu
#+END_SRC

** Vimrc settings
#+BEGIN_SRC vimrc
set ts=2 sw=2 expandtab
set nu
** Used Cli Tools
*** Netcat
[[https://linuxize.com/post/netcat-nc-command-with-examples/][nc examples]]
- Scan for open ports
#+BEGIN_SRC shell
nc -z -v <service name> <port>
#+END_SRC
*** Grep
- S chow more lines after hit
#+BEGIN_SRC shell
grep A<number of lines> <serarch string>
#+END_SRC

#+END_SRC
**  TODO:
- [X] Read [[https://kubernetes.io/docs/tasks/administer-cluster/declare-network-policy/][Declare Network Polilcy]]
- [X] Find out if the servce can be created vie cli
- [X] Repeat Taints and Toleratons
- [ ] Pactice [[https://medium.com/bb-tutorials-and-thoughts/practice-enough-with-these-questions-for-the-ckad-exam-2f42d1228552][150 Questions]]:
- [ ] Understand [[https://blog.nillsf.com/index.php/2019/07/28/ckad-series-part-4-multi-container-pods/][concept]] of sidecar,[[https://bjammal.github.io/2019-08-25-ambasador-pattern/][ambassador]] , Adapter based on that you could alone get 15 marks.
- [ ] Practice game of pods
- [ ] Read Nills [[https://blog.nillsf.com/index.php/category/ckad/][SKAD series]]
- [ ] Read [[https://training.linuxfoundation.org/wp-content/uploads/2019/05/CKA-CKAD-Candidate-Handbook-v1.2-.pdf][Candidate Handbook]]
- [ ] Practice grep syntax


* Test extensions
** Docker
- list imgages
#+begin_src shell
docker images
#+end_src
- build images
#+begin_src shell
docker build -t webapp-color
#+end_src
- run image
#+begin_src shell
docker run -p <hostport>:<container port> <image>
#+end_src
** Kubeconfig file
- locaton
Usally loacated at ~/.kube/config
or see KUBECONFIG environment variable
- params
#+begin_src shell
kubectl config view
#+end_src
- change user context
#+begin_src shell
#To use that context, run the command:
kubectl config --kubeconfig=/root/my-kube-config use-context research
# To know the current context, run the command:
kubectl config --kubeconfig=/root/my-kube-config current-context
#+end_src
*** Usefull config commands
#+begin_src shell
#show the full contents of your kubeconfig file
kubectl config view

#show the value of the current-context line of your kubeconfig file
kubectl config current-context

#show all of the Users currently defined in your kubeconfig file
kubectl config get-users

#show all of the Clusters currently defined in your kubeconfig file
kubectl config get-clusters

#show all of the Contexts currently defined in your kubeconfig file
kubectl config get-contexts

#+end_src
* Exercise notes
** Blitz 1
** Game of Pods
*** Drupal cms
Create Service file:
#+BEGIN_SRC
k create service nodeport drupal-service --node-port=30095 --tcp=80 --dry-run=true -o yaml > drupal_service.yaml
#+END_SRC
- [X] TODO: Read about[[https://kubernetes.io/docs/concepts/workloads/pods/init-containers/][ Init Containers]]
** SCAD Simulator 1
** [[https://medium.com/bb-tutorials-and-thoughts/practice-enough-with-these-questions-for-the-ckad-exam-2f42d1228552][130 Questins]]
*** Multi container Pods
**** Init multipod section
**** 29
#+BEGIN_SRC shell :results output
cd ./testfiles/
kubectl run busybox --image=busybox --dry-run=client -o yaml > mc.yaml
cat mc.yaml
ls
#+END_SRC

#+RESULTS:
#+begin_example
apiVersion: v1
kind: Pod
metadata:
creationTimestamp: null
labels:
run: busybox
name: busybox
spec:
containers:
- image: busybox
name: busybox
resources: {}
dnsPolicy: ClusterFirst
restartPolicy: Always
status: {}
mc.yaml
#+end_example


complete multipod file
#+BEGIN_SRC yaml
apiVersion: v1
kind: Pod
metadata:
creationTimestamp: null
labels:
run: busybox
name: busybox
spec:
containers:
- args:
- bin/sh
- -c
- echo Hello word;sleep 3600
image: busybox
name: busybox1
resources: {}
- args:
- bin/sh
- -c
- echo Hello world;sleep 3600
image: busybox
name: busybox2
- args:
- bin/sh
- -c
- echo this is third container ;sleep 3600
image: busybox
name: busybox3
dnsPolicy: ClusterFirst
restartPolicy: Always
status: {}
#+END_SRC

#+BEGIN_SRC shell :results output
kubectl create -f  mc.yaml
#+END_SRC

#+RESULTS:
: pod/busybox created

#+BEGIN_SRC shell :results output
kubectl describe po busybox
#+END_SRC

#+RESULTS:
#+begin_example
Name:         busybox
Namespace:    default
Priority:     0
Node:         minikube/172.17.0.2
Start Time:   Tue, 20 Oct 2020 11:41:35 +0200
Labels:       run=busybox
Annotations:  <none>
Status:       Running
IP:           172.18.0.6
IPs:
IP:  172.18.0.6
Containers:
busybox1:
Container ID:  docker://a8a84bb695b64a75103ee7f896d9333abed7492a941627fd246c15bcbbfedc6f
Image:         busybox
Image ID:      docker-pullable://busybox@sha256:a9286defaba7b3a519d585ba0e37d0b2cbee74ebfe590960b0b1d6a5e97d1e1d
Port:          <none>
Host Port:     <none>
Args:
    bin/sh
    -c
    echo Hello word;sleep 3600
State:          Running
    Started:      Tue, 20 Oct 2020 11:41:38 +0200
Ready:          True
Restart Count:  0
Environment:    <none>
Mounts:
    /var/run/secrets/kubernetes.io/serviceaccount from default-token-qpgrj (ro)
busybox2:
Container ID:  docker://7bf844d973e73bdeee3cf907fabb98e0f825457d328d8c9d7fa1da38e365f40c
Image:         busybox
Image ID:      docker-pullable://busybox@sha256:a9286defaba7b3a519d585ba0e37d0b2cbee74ebfe590960b0b1d6a5e97d1e1d
Port:          <none>
Host Port:     <none>
Args:
    bin/sh
    -c
    echo Hello world;sleep 3600
State:          Running
    Started:      Tue, 20 Oct 2020 11:41:40 +0200
Ready:          True
Restart Count:  0
Environment:    <none>
Mounts:
    /var/run/secrets/kubernetes.io/serviceaccount from default-token-qpgrj (ro)
busybox3:
Container ID:  docker://5b7c2909ee0d1cae50aa5d03a853032b00d0fd23558ec156f13076ef33e62b1c
Image:         busybox
Image ID:      docker-pullable://busybox@sha256:a9286defaba7b3a519d585ba0e37d0b2cbee74ebfe590960b0b1d6a5e97d1e1d
Port:          <none>
Host Port:     <none>
Args:
    bin/sh
    -c
    echo this is third container ;sleep 3600
State:          Running
    Started:      Tue, 20 Oct 2020 11:41:42 +0200
Ready:          True
Restart Count:  0
Environment:    <none>
Mounts:
    /var/run/secrets/kubernetes.io/serviceaccount from default-token-qpgrj (ro)
Conditions:
Type              Status
Initialized       True
Ready             True
ContainersReady   True
PodScheduled      True
Volumes:
default-token-qpgrj:
Type:        Secret (a volume populated by a Secret)
SecretName:  default-token-qpgrj
Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                node.kubernetes.io/unreachable:NoExecute for 300s
Events:
Type    Reason     Age        From               Message
----    ------     ----       ----               -------
Normal  Scheduled  <unknown>                     Successfully assigned default/busybox to minikube
Normal  Pulling    47s        kubelet, minikube  Pulling image "busybox"
Normal  Pulled     45s        kubelet, minikube  Successfully pulled image "busybox" in 2.055967s
Normal  Created    45s        kubelet, minikube  Created container busybox1
Normal  Started    45s        kubelet, minikube  Started container busybox1
Normal  Pulling    45s        kubelet, minikube  Pulling image "busybox"
Normal  Pulled     43s        kubelet, minikube  Successfully pulled image "busybox" in 1.9051111s
Normal  Created    43s        kubelet, minikube  Created container busybox2
Normal  Started    43s        kubelet, minikube  Started container busybox2
Normal  Pulling    43s        kubelet, minikube  Pulling image "busybox"
Normal  Pulled     41s        kubelet, minikube  Successfully pulled image "busybox" in 2.1070341s
Normal  Created    41s        kubelet, minikube  Created container busybox3
Normal  Started    41s        kubelet, minikube  Started container busybox3
#+end_example

**** 30
#+BEGIN_SRC shell
kubectl logs busybox -c busybox1
#+END_SRC

#+RESULTS:
: Hello word

#+BEGIN_SRC shell
kubectl logs busybox -c busybox3
#+END_SRC

#+RESULTS:
: this is third container

**** 32 Run the command in the third container
#+BEGIN_SRC shell :results output
kubectl exec busybox -c busybox3  -- ls
#+END_SRC

#+RESULTS:
#+begin_example
bin
dev
etc
home
proc
root
sys
tmp
usr
var
#+end_example
**** 33 Show metrics of the containers
#+BEGIN_SRC shell :results output
kubectl top pod busybox --containers
#+END_SRC

**** 34 Create pod with sidecar container
#+BEGIN_SRC shell :results output
cd testfiles
kubectl run busybox_sidecar --image=busybox  --dry-run=client -o yaml -- bin/sh -c "while true;do echo 'Hi I am from Main Container' >> /var/log/index.html;sleep 5;done"> busybox_sidecar.yml
cat busybox_sidecar.yml
#+END_SRC

#+RESULTS:
#+begin_example
apiVersion: v1
kind: Pod
metadata:
creationTimestamp: null
labels:
run: busybox_sidecar
name: busybox_sidecar
spec:
containers:
- args:
- bin/sh
- -c
- while true;do echo 'Hi I am from Main Container' >> /var/log/index.html;sleep
    5;done
image: busybox
name: busybox_sidecar
resources: {}
dnsPolicy: ClusterFirst
restartPolicy: Always
status: {}
#+end_example

- [ ] ToDo How to impl. Sidecar and Embassador pattern exactly

#+BEGIN_SRC shell :results output
cd testfiles
kubectl create -f busybox_sidecar.yml
#+END_SRC

#+RESULTS:
: pod/busybox-sidecar created

#+BEGIN_SRC shell :results output
kubectl describe po busybox-sidecar
#+END_SRC

#+RESULTS:
#+begin_example
Name:         busybox-sidecar
Namespace:    default
Priority:     0
Node:         minikube/172.17.0.2
Start Time:   Tue, 20 Oct 2020 14:25:52 +0200
Labels:       run=busybox-sidecar
Annotations:  <none>
Status:       Running
IP:           172.18.0.8
IPs:
IP:  172.18.0.8
Containers:
sidecar-container:
    Container ID:   docker://34ee9fd9e1a8c216fd585581e86731050378dd3f5471e791a2bcba62a0ace328
    Image:          nginx
    Image ID:       docker-pullable://nginx@sha256:ed7f815851b5299f616220a63edac69a4cc200e7f536a56e421988da82e44ed8
    Port:           80/TCP
    Host Port:      0/TCP
    State:          Running
    Started:      Tue, 20 Oct 2020 14:25:55 +0200
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
    /usr/share/nginx/html from var-logs (rw)
    /var/run/secrets/kubernetes.io/serviceaccount from default-token-qpgrj (ro)
main-container:
    Container ID:  docker://163038776eb6f9ee5591aa4ec5a4d0b56397366c5dad505b57a746a51202029a
    Image:         busybox
    Image ID:      docker-pullable://busybox@sha256:a9286defaba7b3a519d585ba0e37d0b2cbee74ebfe590960b0b1d6a5e97d1e1d
    Port:          <none>
    Host Port:     <none>
    Args:
    bin/sh
    -c
    while true; do
        echo 'Hi I am from Main Container' >> /var/log/index.html;
        sleep 5;
    done

    State:          Running
    Started:      Tue, 20 Oct 2020 14:25:57 +0200
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
    /var/logs from var-logs (rw)
    /var/run/secrets/kubernetes.io/serviceaccount from default-token-qpgrj (ro)
Conditions:
Type              Status
Initialized       True
Ready             True
ContainersReady   True
PodScheduled      True
Volumes:
var-logs:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:
    SizeLimit:  <unset>
default-token-qpgrj:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-qpgrj
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                node.kubernetes.io/unreachable:NoExecute for 300s
Events:
Type    Reason     Age        From               Message
----    ------     ----       ----               -------
Normal  Scheduled  <unknown>                     Successfully assigned default/busybox-sidecar to minikube
Normal  Pulling    2m8s       kubelet, minikube  Pulling image "nginx"
Normal  Pulled     2m5s       kubelet, minikube  Successfully pulled image "nginx" in 2.3070851s
Normal  Created    2m5s       kubelet, minikube  Created container sidecar-container
Normal  Started    2m5s       kubelet, minikube  Started container sidecar-container
Normal  Pulling    2m5s       kubelet, minikube  Pulling image "busybox"
Normal  Pulled     2m3s       kubelet, minikube  Successfully pulled image "busybox" in 2.3570642s
Normal  Created    2m3s       kubelet, minikube  Created container main-container
Normal  Started    2m3s       kubelet, minikube  Started container main-container
#+end_example

**** 35 Exec containers
- Exec into main container
#+BEGIN_SRC shell :results outputdgydrfffrtuuuut
kubectl exec -it busybox-sidecar -c main-container -- sh
#+END_SRC


*** Pod Design
**** 36 Pods with label information
#+BEGIN_SRC shell :result output
kubectl get pods --show-labels
#+END_SRC

#+RESULTS:
| NAME            | READY | STATUS  | RESTARTS | AGE   | LABELS              |
| busybox         | 3/3   | Running |       15 | 5h32m | run=busybox         |
| busybox-sidecar | 2/2   | Running |        0 | 168m  | run=busybox-sidecar |
| counter         | 3/3   | Running |        0 | 174m  | <none>              |
| nginx           | 1/1   | Running |        0 | 7h44m | run=nginx           |
| nginx-dev1      | 1/1   | Running |        0 | 8m6s  | env=dev             |
| nginx-dev2      | 1/1   | Running |        0 | 8m6s  | env=dev             |
| nginx-dev3      | 1/1   | Running |        0 | 8m6s  | env=dev             |
| nginx2          | 0/1   | Error   |        0 | 8h    | run=nginx2          |
| pod-readines    | 1/1   | Running |        1 | 3d23h | run=pod-readines    |
| test            | 1/1   | Running |        1 | 4d    | run=test            |

**** 37 Create nginx pods
- create pods
#+BEGIN_SRC shell :results output
kubectl run nginx-dev1 --image=nginx --labels=env=dev
kubectl run nginx-dev2 --image=nginx --labels=env=dev
kubectl run nginx-dev3 --image=nginx --labels=env=dev
#+END_SRC

#+RESULTS:
: pod/nginx-dev1 created
: pod/nginx-dev2 created
: pod/nginx-dev3 created

- verify pod labels
#+BEGIN_SRC shell :results output
kubectl get pods --show-labels
#+END_SRC

#+RESULTS:
#+begin_example
NAME              READY   STATUS    RESTARTS   AGE     LABELS
busybox           3/3     Running   15         5h26m   run=busybox
busybox-sidecar   2/2     Running   0          162m    run=busybox-sidecar
counter           3/3     Running   0          168m    <none>
nginx             1/1     Running   0          7h38m   run=nginx
nginx-dev1        1/1     Running   0          115s    env=dev
nginx-dev2        1/1     Running   0          115s    env=dev
nginx-dev3        1/1     Running   0          115s    env=dev
nginx2            0/1     Error     0          8h      run=nginx2
pod-readines      1/1     Running   1          3d22h   run=pod-readines
test              1/1     Running   1          4d      run=test
#+end_example

- filter labels
#+BEGIN_SRC shell :results output
kubectl get pods -l env=dev
#+END_SRC

#+RESULTS:
: NAME         READY   STATUS    RESTARTS   AGE
: nginx-dev1   1/1     Running   0          6m19s
: nginx-dev2   1/1     Running   0          6m19s
: nginx-dev3   1/1     Running   0          6m19s

- change label
#+BEGIN_SRC shell :results output
kubectl label pod nginx-dev3 env=uat --overwrite
kubectl get pods --show-labels
#+END_SRC

**** 65 Get yaml of rs and po from deployment
#+BEGIN_SRC shell :result output
kubectl get rs -l <label> -o yaml
kubectl get po -l <label> -o yaml
#+END_SRC

**** 68 Update Image
#+BEGIN_SRC shell :results output
kubectl set image deploy <name> <image>=<image:new version>
#+END_SRC

#+RESULTS:

** KodeKloud
*** Configuration
***** Cmmands and Arguments
*** ClusterRoles
**** Inspect environment
#+begin_quote
Inspect the environment and identify the authorization modes configured on the cluster.
Check the kube-apiserver settings.
#+end_quote
#+begin_src shell
kubectl describe pod kube-apiserver-controlplane -n kube-system

#+end_src

 #+begin_quote
What are the resources the kube-proxy role in the kube-system namespace is given access to?
 #+end_quote
#+begin_src shell
kubectl get roles -A
kubectl describe role kube-proxy -n kube-system

#+end_src
**** Edit role
#+begin_src shell
kubctl edit role developer -n blue
#+end_src
*** Admission Controllers
#+begin_quote
Which admission controller is enabled in this cluster which is normally disabled?
#+end_quote

#+begin_src shell
to chesck admission plugin ,
/etc/kubernetes/maifests/kube-apiserver.yaml
check --enable-admission-plugins
#+end_src

#+begin_src shell
#check running plugins
ps -ef | grep kube-apiserver | grep admission-plugins
#+end_src
#+RESULTS:
*** Validating and Mutating Admission Containers
-
